print(new_img1)
## Get face detection from getgooglevision
PicVisionStatsFaceNew1 = getGoogleVisionResponse("./ExplicitImages/gif1.jpeg",feature = 'FACE_DETECTION',numResults = 40)
PicVisionStatsFaceNew2 = getGoogleVisionResponse("./ExplicitImages/gif2.jpeg",feature = 'FACE_DETECTION',numResults = 40)
PicVisionStatsFaceNew3 = getGoogleVisionResponse("./ExplicitImages/gif3.jpeg",feature = 'FACE_DETECTION',numResults = 40)
PicVisionStatsFaceNew4 = getGoogleVisionResponse("./ExplicitImages/gif4.jpeg",feature = 'FACE_DETECTION',numResults = 40)
PicVisionStatsFaceNew5 = getGoogleVisionResponse("./ExplicitImages/gif5.jpeg",feature = 'FACE_DETECTION',numResults = 40)
PicVisionStatsFaceNew6 = getGoogleVisionResponse("./ExplicitImages/gif6.jpeg",feature = 'FACE_DETECTION',numResults = 40)
PicVisionStatsFaceNew7 = getGoogleVisionResponse("./ExplicitImages/gif7.jpeg",feature = 'FACE_DETECTION',numResults = 40)
PicVisionStatsFaceNew8 = getGoogleVisionResponse("./ExplicitImages/gif7.jpeg",feature = 'FACE_DETECTION',numResults = 40)
## Generating boundry for the face
xs1 <- PicVisionStatsFaceNew1$fdBoundingPoly$vertices[[1]][1][[1]]
ys1 <- PicVisionStatsFaceNew1$fdBoundingPoly$vertices[[1]][2][[1]]
## Generating landmarks
xs2 = PicVisionStatsFaceNew1$landmarks[[1]][[2]][[1]]
ys2 = PicVisionStatsFaceNew1$landmarks[[1]][[2]][[2]]
img <- image_read("./ExplicitImages/gif1.jpeg")
new_img1 <- image_draw(img)
rect(xs1[1],ys1[1],xs1[3],ys1[3],border = "red", lty = "dashed", lwd = 1)
points(xs2,ys2,col="red",cex=0.9)
dev.off()
print(new_img1)
## Generating boundry for the face
xs1 <- PicVisionStatsFaceNew2$fdBoundingPoly$vertices[[1]][1][[1]]
ys1 <- PicVisionStatsFaceNew2$fdBoundingPoly$vertices[[1]][2][[1]]
## Generating landmarks
xs2 = PicVisionStatsFaceNew2$landmarks[[1]][[2]][[1]]
ys2 = PicVisionStatsFaceNew2$landmarks[[1]][[2]][[2]]
img <- image_read("./ExplicitImages/gif2.jpeg")
new_img2 <- image_draw(img)
rect(xs1[1],ys1[1],xs1[3],ys1[3],border = "red", lty = "dashed", lwd = 1)
points(xs2,ys2,col="red",cex=0.9)
dev.off()
print(new_img2)
## Generating boundry for the face
xs1 <- PicVisionStatsFaceNew3$fdBoundingPoly$vertices[[1]][1][[1]]
ys1 <- PicVisionStatsFaceNew3$fdBoundingPoly$vertices[[1]][2][[1]]
## Generating landmarks
xs2 = PicVisionStatsFaceNew3$landmarks[[1]][[2]][[1]]
ys2 = PicVisionStatsFaceNew3$landmarks[[1]][[2]][[2]]
img <- image_read("./ExplicitImages/gif3.jpeg")
new_img3 <- image_draw(img)
rect(xs1[1],ys1[1],xs1[3],ys1[3],border = "red", lty = "dashed", lwd = 1)
points(xs2,ys2,col="red",cex=0.9)
dev.off()
print(new_img3)
## Generating boundry for the face
xs1 <- PicVisionStatsFaceNew4$fdBoundingPoly$vertices[[1]][1][[1]]
ys1 <- PicVisionStatsFaceNew4$fdBoundingPoly$vertices[[1]][2][[1]]
## Generating landmarks
xs2 = PicVisionStatsFaceNew4$landmarks[[1]][[2]][[1]]
ys2 = PicVisionStatsFaceNew4$landmarks[[1]][[2]][[2]]
img <- image_read("./ExplicitImages/gif4.jpeg")
new_img4 <- image_draw(img)
rect(xs1[1],ys1[1],xs1[3],ys1[3],border = "red", lty = "dashed", lwd = 1)
points(xs2,ys2,col="red",cex=0.9)
dev.off()
print(new_img3)
xs1 <- PicVisionStatsFaceNew5$fdBoundingPoly$vertices[[1]][1][[1]]
ys1 <- PicVisionStatsFaceNew5$fdBoundingPoly$vertices[[1]][2][[1]]
## Generating landmarks
xs2 = PicVisionStatsFaceNew5$landmarks[[1]][[2]][[1]]
ys2 = PicVisionStatsFaceNew5$landmarks[[1]][[2]][[2]]
#
# img <- image_read("https://78.media.tumblr.com/554760cdbb113582267efcb0ed024f64/tumblr_oyah4aLVCr1rpubqio2_400.gif")
img <- image_read("./ExplicitImages/gif5.jpeg")
new_img5 <- image_draw(img)
rect(xs1[1],ys1[1],xs1[3],ys1[3],border = "red", lty = "dashed", lwd = 1)
points(xs2,ys2,col="red",cex=0.9)
dev.off()
xs1 <- PicVisionStatsFaceNew6$fdBoundingPoly$vertices[[1]][1][[1]]
ys1 <- PicVisionStatsFaceNew6$fdBoundingPoly$vertices[[1]][2][[1]]
## Generating landmarks
xs2 = PicVisionStatsFaceNew6$landmarks[[1]][[2]][[1]]
ys2 = PicVisionStatsFaceNew6$landmarks[[1]][[2]][[2]]
#
# img <- image_read("https://78.media.tumblr.com/554760cdbb113582267efcb0ed024f64/tumblr_oyah4aLVCr1rpubqio2_400.gif")
img <- image_read("./ExplicitImages/gif6.jpeg")
new_img6 <- image_draw(img)
rect(xs1[1],ys1[1],xs1[3],ys1[3],border = "red", lty = "dashed", lwd = 1)
points(xs2,ys2,col="red",cex=0.9)
dev.off()
xs1 <- PicVisionStatsFaceNew7$fdBoundingPoly$vertices[[1]][1][[1]]
ys1 <- PicVisionStatsFaceNew7$fdBoundingPoly$vertices[[1]][2][[1]]
## Generating landmarks
xs2 = PicVisionStatsFaceNew7$landmarks[[1]][[2]][[1]]
ys2 = PicVisionStatsFaceNew7$landmarks[[1]][[2]][[2]]
#
# img <- image_read("https://78.media.tumblr.com/554760cdbb113582267efcb0ed024f64/tumblr_oyah4aLVCr1rpubqio2_400.gif")
img <- image_read("./ExplicitImages/gif7.jpeg")
new_img7 <- image_draw(img)
rect(xs1[1],ys1[1],xs1[3],ys1[3],border = "red", lty = "dashed", lwd = 1)
points(xs2,ys2,col="red",cex=0.9)
dev.off()
xs1 <- PicVisionStatsFaceNew8$fdBoundingPoly$vertices[[1]][1][[1]]
ys1 <- PicVisionStatsFaceNew8$fdBoundingPoly$vertices[[1]][2][[1]]
## Generating landmarks
xs2 = PicVisionStatsFaceNew8$landmarks[[1]][[2]][[1]]
ys2 = PicVisionStatsFaceNew8$landmarks[[1]][[2]][[2]]
#
# img <- image_read("https://78.media.tumblr.com/554760cdbb113582267efcb0ed024f64/tumblr_oyah4aLVCr1rpubqio2_400.gif")
img <- image_read("./ExplicitImages/gif8.jpeg")
new_img8 <- image_draw(img)
rect(xs1[1],ys1[1],xs1[3],ys1[3],border = "red", lty = "dashed", lwd = 1)
points(xs2,ys2,col="red",cex=0.9)
dev.off()
print(new_img8)
print(new_img7)
print(new_img6)
print(new_img5)
print(new_img4)
print(new_img3)
print(new_img2)
print(new_img1)
image_morph(c(new_img1, new_img2,new_img3,new_img4,new_img5,new_img6,new_img7,new_img8), frames = 10)
frames <- image_morph(c(new_img1, new_img2,new_img3,new_img4,new_img5,new_img6,new_img7,new_img8), frames = 10)
image_animate(frames)
frames <- image_morph(c(new_img1, new_img2,new_img3,new_img4,new_img5,new_img6,new_img7,new_img8), frames = 50)
image_animate(frames)
frames <- image_morph(c(new_img1, new_img2,new_img3,new_img4,new_img5,new_img6,new_img7,new_img8), frames = 2)
image_animate(frames)
frames <- image_morph(c(new_img1, new_img2,new_img3,new_img4,new_img5,new_img6,new_img7,new_img8), frames = 5)
image_animate(frames)
frames <- image_morph(c(new_img1, new_img2,new_img3,new_img4,new_img5,new_img6,new_img7,new_img8), frames = 1)
image_animate(frames)
frames <- image_morph(c(new_img1, new_img2,new_img3,new_img4,new_img5,new_img6,new_img7,new_img8), frames = 0.25)
image_animate(frames)
frames <- image_morph(c(new_img1, new_img2,new_img3,new_img4,new_img5,new_img6,new_img7,new_img8), frames = 0.05)
image_animate(frames)
frames <- image_morph(c(new_img1, new_img2,new_img3,new_img4,new_img5,new_img6,new_img7,new_img8), frames = 0.025)
image_animate(frames)
frames <- image_morph(c(new_img1, new_img2,new_img3,new_img4,new_img5,new_img6,new_img7,new_img8), frames = 0.0025)
image_animate(frames)
PicVisionStatsFaceNew1
xs1
ys1
xs2
ys2
View(PicVisionStatsFaceNew2)
list8 <- list(xs1,ys1,xs2,ys2,PicVisionStatsFaceNew8)
View(list8)
list.all <- vector(mode = "list",length = 7)
list.all <- vector(mode = "list",length = length(img))
length(img)
## Drawing the dots for the image
img <- image_read("./ExplicitImages/giphy.gif")
print(img)
list.all <- vector(mode = "list",length = length(img))
for( i in seq(length(img))){
image_name <- paste("./ExplicitImages/gif",i,".jpeg",sep = "")
image_write(img[i],path=image_name,format = "jpeg")
}
## Get face detection from getgooglevision
PicVisionStatsFaceNew1 = getGoogleVisionResponse(image_name,feature = 'FACE_DETECTION',numResults = 40)
PicVisionStatsFaceNew1
list.all <- vector(mode = "list",length = length(img))
for( i in seq(length(img))){
image_name <- paste("./ExplicitImages/gif",i,".jpeg",sep = "")
image_write(img[i],path=image_name,format = "jpeg")
list[[i]] <- list(xs1,ys1,xs2,ys2,PicVisionStatsFaceNew8)
}
for( i in seq(length(img))){
image_name <- paste("./ExplicitImages/gif",i,".jpeg",sep = "")
image_write(img[i],path=image_name,format = "jpeg")
list.all[[i]] <- list(xs1,ys1,xs2,ys2,PicVisionStatsFaceNew8)
}
View(list.all)
## Drawing the dots for the image
img <- image_read("./ExplicitImages/giphy.gif")
print(img)
list.all <- vector(mode = "list",length = length(img))
for( i in seq(length(img))){
image_name <- paste("./ExplicitImages/gif",i,".jpeg",sep = "")
image_write(img[i],path=image_name,format = "jpeg")
PicVisionStatsFace = getGoogleVisionResponse(image_name,feature = 'FACE_DETECTION',numResults = 40)
## Generating boundry for the face
xs1 <- PicVisionStatsFace$fdBoundingPoly$vertices[[1]][1][[1]]
ys1 <- PicVisionStatsFace$fdBoundingPoly$vertices[[1]][2][[1]]
## Generating landmarks
xs2 = PicVisionStatsFace$landmarks[[1]][[2]][[1]]
ys2 = PicVisionStatsFace$landmarks[[1]][[2]][[2]]
#
list.all[[i]] <- list(xs1,ys1,xs2,ys2,PicVisionStatsFace)
}
library(magick)               # library for image manipulation
library(googleAuthR)          # library for authorizing Google cloud access
library(RoogleVision)         # library for Google Vision API calls
library(tidyverse)            #
library(RCurl)
## Setup the google authentication
## client id and secret id is stored in the environe file
options("googleAuthR.client_id" = Sys.getenv("google_client_id"))
options("googleAuthR.client_secret" = Sys.getenv("google_secret.id"))
options("googleAuthR.scopes.selected" = c("https://www.googleapis.com/auth/cloud-platform"))
googleAuthR::gar_auth()
## Drawing the dots for the image
img <- image_read("./ExplicitImages/giphy.gif")
print(img)
list.all <- vector(mode = "list",length = length(img))
for( i in seq(length(img))){
image_name <- paste("./ExplicitImages/gif",i,".jpeg",sep = "")
image_write(img[i],path=image_name,format = "jpeg")
PicVisionStatsFace = getGoogleVisionResponse(image_name,feature = 'FACE_DETECTION',numResults = 40)
## Generating boundry for the face
xs1 <- PicVisionStatsFace$fdBoundingPoly$vertices[[1]][1][[1]]
ys1 <- PicVisionStatsFace$fdBoundingPoly$vertices[[1]][2][[1]]
## Generating landmarks
xs2 = PicVisionStatsFace$landmarks[[1]][[2]][[1]]
ys2 = PicVisionStatsFace$landmarks[[1]][[2]][[2]]
#
list.all[[i]] <- list(xs1,ys1,xs2,ys2,PicVisionStatsFace)
}
for( i in seq(length(img))){
image_name <- paste("./ExplicitImages/gif",i,".jpeg",sep = "")
image_write(img[i],path=image_name,format = "jpeg")
PicVisionStatsFace = getGoogleVisionResponse(image_name,feature = 'FACE_DETECTION',numResults = 40)
## Generating boundry for the face
xs1 <- PicVisionStatsFace$fdBoundingPoly$vertices[[1]][1][[1]]
ys1 <- PicVisionStatsFace$fdBoundingPoly$vertices[[1]][2][[1]]
## Generating landmarks
xs2 = PicVisionStatsFace$landmarks[[1]][[2]][[1]]
ys2 = PicVisionStatsFace$landmarks[[1]][[2]][[2]]
#
list.all[[i]] <- list(xs1,ys1,xs2,ys2,PicVisionStatsFace)
}
View(list.all)
list.all[[1]]
list.all[[1]][1]
new_img1
list.all[[1]][1][1]
xs1
xs1[1]
list.all[[1]][1,1]
list.all[[1]][1]
unlist(list.all[[1]][1])[1]
list.all[[5]][1]
unlist(list.all[[5]][5])
unlist(list.all[[5]][5])[1]
new_img8 <- image_draw(img)
rect(xs1[1],ys1[1],xs1[3],ys1[3],border = "red", lty = "dashed", lwd = 1)
points(xs2,ys2,col="red",cex=0.9)
dev.off()
new_img1
new_img8
class(new_img8)
#### Get the face detection data from
####
for( i in seq(length(img))){
image_name <- paste("./ExplicitImages/gif",i,".jpeg",sep = "")
image_write(img[i],path=image_name,format = "jpeg")
PicVisionStatsFace = getGoogleVisionResponse(image_name,feature = 'FACE_DETECTION',numResults = 40)
## Generating boundry for the face
xs1 <- PicVisionStatsFace$fdBoundingPoly$vertices[[1]][1][[1]]
ys1 <- PicVisionStatsFace$fdBoundingPoly$vertices[[1]][2][[1]]
## Generating landmarks
xs2 = PicVisionStatsFace$landmarks[[1]][[2]][[1]]
ys2 = PicVisionStatsFace$landmarks[[1]][[2]][[2]]
#
list.all[[i]] <- list(xs1,ys1,xs2,ys2)
}
View(list.all)
length(list.all)
list(new_img8)
list.all.image <- vector(mode = "list",length = length(img))
list.all[[1]]
list.all[[1]][1]
list.all[[1]][1][1]
unlist(list.all[[1]][1])[1]
### Recreate the gif from the frames --- Not a good way to do it.
unlist(list.all[[1]][3])
list.all.image <- vector(mode = "list",length = length(img))
for (i in seq(length(list.all))){
image_name <- paste("./ExplicitImages/gif",i,".jpeg",sep = "")
new_img <- image_draw(image_name)
rect(unlist(list.all[[i]][1])[1],unlist(list.all[[1]][2])[1],unlist(list.all[[1]][1])[3],unlist(list.all[[1]][2])[3],border = "red", lty = "dashed", lwd = 1)
points(unlist(list.all[[i]][3]),unlist(list.all[[i]][4]),col="red",cex=0.9)
dev.off()
list.all.image[[i]] <- new_img
}
for (i in seq(length(list.all))){
image_name <- paste("./ExplicitImages/gif",i,".jpeg",sep = "")
img <- image_read(image_name)
new_img <- image_draw(img)
rect(unlist(list.all[[i]][1])[1],unlist(list.all[[1]][2])[1],unlist(list.all[[1]][1])[3],unlist(list.all[[1]][2])[3],border = "red", lty = "dashed", lwd = 1)
points(unlist(list.all[[i]][3]),unlist(list.all[[i]][4]),col="red",cex=0.9)
dev.off()
list.all.image[[i]] <- new_img
}
View(list.all.image)
print(list.all.image[[1]])
print(list.all.image[[2]])
print(list.all.image[[3]])
print(list.all.image[[4]])
print(list.all.image[[5]])
print(list.all.image[[6]])
print(list.all.image[[7]])
print(list.all.image[[8]])
list.all.image <- vector(mode = "list",length = length(img))
for (i in seq(length(list.all))){
image_name <- paste("./ExplicitImages/gif",i,".jpeg",sep = "")
img <- image_read(image_name)
new_img <- image_draw(img)
rect(unlist(list.all[[i]][1])[1],unlist(list.all[[i]][2])[1],unlist(list.all[[i]][1])[3],unlist(list.all[[i]][2])[3],border = "red", lty = "dashed", lwd = 1)
points(unlist(list.all[[i]][3]),unlist(list.all[[i]][4]),col="red",cex=0.9)
dev.off()
list.all.image[[i]] <- new_img
}
c(unlist(list.all.image))
frames <- image_morph(c(unlist(list.all.image)), frames = 0.0025)
frames <- image_morph(unlist(list.all.image), frames = 0.0025)
frames <- image_morph(list.all.image, frames = 0.0025)
frames <- image_morph(c(list.all.image[[1]],list.all.image[[2]]), frames = 0.0025)
image_animate(frames)
list.all.image
unlist(list.all.image)
c(unlist(list.all.image))
image_animate(frames)
for (i in seq(length(list.all))){
image_name <- paste("./ExplicitImages/gif",i,".jpeg",sep = "")
img <- image_read(image_name)
new_img <- image_draw(img)
rect(unlist(list.all[[i]][1])[1],unlist(list.all[[i]][2])[1],unlist(list.all[[i]][1])[3],unlist(list.all[[i]][2])[3],border = "red", lty = "dashed", lwd = 1)
points(unlist(list.all[[i]][3]),unlist(list.all[[i]][4]),col="red",cex=0.9)
dev.off()
list.all.image_c <- c(list.all.image_c,new_img)
}
list.all.image_c <- vector(mode = "character" )
for (i in seq(length(list.all))){
image_name <- paste("./ExplicitImages/gif",i,".jpeg",sep = "")
img <- image_read(image_name)
new_img <- image_draw(img)
rect(unlist(list.all[[i]][1])[1],unlist(list.all[[i]][2])[1],unlist(list.all[[i]][1])[3],unlist(list.all[[i]][2])[3],border = "red", lty = "dashed", lwd = 1)
points(unlist(list.all[[i]][3]),unlist(list.all[[i]][4]),col="red",cex=0.9)
dev.off()
list.all.image_c <- c(list.all.image_c,new_img)
}
View(list.all.image_c)
image_animate(frames)
frames
list.all.image_c <- vector(mode="character")
for (i in seq(length(list.all))){
image_name <- paste("./ExplicitImages/gif",i,".jpeg",sep = "")
img <- image_read(image_name)
new_img <- image_draw(img)
rect(unlist(list.all[[i]][1])[1],unlist(list.all[[i]][2])[1],unlist(list.all[[i]][1])[3],unlist(list.all[[i]][2])[3],border = "red", lty = "dashed", lwd = 1)
points(unlist(list.all[[i]][3]),unlist(list.all[[i]][4]),col="red",cex=0.9)
dev.off()
if (i==1){
list.all.image_c <- new_img
} else
{
list.all.image_c <- c(list.all.image_c,new_img)
}
list.all.image[[i]] <- new_img
}
frames <- image_morph(list.all.image_c, frames = 0.0025)
image_animate(frames)
library(magick)               # library for image manipulation
library(googleAuthR)          # library for authorizing Google cloud access
library(RoogleVision)         # library for Google Vision API calls
library(tidyverse)            #
library(RCurl)
## Setup the google authentication
## client id and secret id is stored in the environe file
options("googleAuthR.client_id" = Sys.getenv("google_client_id"))
options("googleAuthR.client_secret" = Sys.getenv("google_secret.id"))
options(
"googleAuthR.scopes.selected" = c("https://www.googleapis.com/auth/cloud-platform")
)
googleAuthR::gar_auth()
## Drawing the dots for the image
img <- image_read("../ExplicitImages/giphy.gif")
print(img)
list.all <- vector(mode = "list", length = length(img))
#### Get the face detection data from google
for (i in seq(length(img))) {
image_name <- paste("../ExplicitImages/gif", i, ".jpeg", sep = "")
image_write(img[i], path = image_name, format = "jpeg")
PicVisionStatsFace = getGoogleVisionResponse(image_name, feature = 'FACE_DETECTION', numResults = 40)
## Generating boundry for the face
xs1 <- PicVisionStatsFace$fdBoundingPoly$vertices[[1]][1][[1]]
ys1 <- PicVisionStatsFace$fdBoundingPoly$vertices[[1]][2][[1]]
## Generating landmarks like nose, eye brows
xs2 = PicVisionStatsFace$landmarks[[1]][[2]][[1]]
ys2 = PicVisionStatsFace$landmarks[[1]][[2]][[2]]
#
list.all[[i]] <- list(xs1, ys1, xs2, ys2)
}
#list.all.image <- vector(mode = "list", length = length(img))
list.all.image_c <- vector(mode = "character")
for (i in seq(length(list.all))) {
image_name <- paste("../ExplicitImages/gif", i, ".jpeg", sep = "")
img <- image_read(image_name)
new_img <- image_draw(img)
rect(
unlist(list.all[[i]][1])[1],
unlist(list.all[[i]][2])[1],
unlist(list.all[[i]][1])[3],
unlist(list.all[[i]][2])[3],
border = "red",
lty = "dashed",
lwd = 1
)
points(unlist(list.all[[i]][3]),
unlist(list.all[[i]][4]),
col = "red",
cex = 0.9)
dev.off()
if (i == 1) {
list.all.image_c <- new_img
} else
{
list.all.image_c <- c(list.all.image_c, new_img)
}
#  list.all.image[[i]] <- new_img
}
frames <- image_morph(list.all.image_c, frames = 0.0025)
image_animate(frames)
library(magick)
library(magick)               # library for image manipulation
library(googleAuthR)          # library for authorizing Google cloud access
library(RoogleVision)         # library for Google Vision API calls
library(tidyverse)            #
library(RCurl)
## Setup the google authentication
## client id and secret id is stored in the environe file
options("googleAuthR.client_id" = Sys.getenv("google_client_id"))
options("googleAuthR.client_secret" = Sys.getenv("google_secret.id"))
options(
"googleAuthR.scopes.selected" = c("https://www.googleapis.com/auth/cloud-platform")
)
googleAuthR::gar_auth()
## Drawing the dots for the image
img <- image_read("./ExplicitImages/giphy.gif")
print(img)
list.all <- vector(mode = "list", length = length(img))
#### Get the face detection data from google
for (i in seq(length(img))) {
image_name <- paste("./ExplicitImages/gif", i, ".jpeg", sep = "")
image_write(img[i], path = image_name, format = "jpeg")
PicVisionStatsFace = getGoogleVisionResponse(image_name, feature = 'FACE_DETECTION', numResults = 40)
## Generating boundry for the face
xs1 <- PicVisionStatsFace$fdBoundingPoly$vertices[[1]][1][[1]]
ys1 <- PicVisionStatsFace$fdBoundingPoly$vertices[[1]][2][[1]]
## Generating landmarks
xs2 = PicVisionStatsFace$landmarks[[1]][[2]][[1]]
ys2 = PicVisionStatsFace$landmarks[[1]][[2]][[2]]
#
list.all[[i]] <- list(xs1, ys1, xs2, ys2)
}
### Recreate the gif from the frames --- Not a good way to do it.
unlist(list.all[[1]][3])
list.all.image <- vector(mode = "list", length = length(img))
list.all.image_c <- vector(mode = "character")
for (i in seq(length(list.all))) {
image_name <- paste("./ExplicitImages/gif", i, ".jpeg", sep = "")
img <- image_read(image_name)
new_img <- image_draw(img)
rect(
unlist(list.all[[i]][1])[1],
unlist(list.all[[i]][2])[1],
unlist(list.all[[i]][1])[3],
unlist(list.all[[i]][2])[3],
border = "red",
lty = "dashed",
lwd = 1
)
points(unlist(list.all[[i]][3]),
unlist(list.all[[i]][4]),
col = "red",
cex = 0.9)
dev.off()
if (i == 1) {
list.all.image_c <- new_img
} else
{
list.all.image_c <- c(list.all.image_c, new_img)
}
#  list.all.image[[i]] <- new_img
}
frames <- image_morph(list.all.image_c, frames = 0.0025)
image_animate(frames)
knitr::opts_chunk$set(echo = TRUE)
library(magick)               # library for image manipulation
library(googleAuthR)          # library for authorizing Google cloud access
library(RoogleVision)         # library for Google Vision API calls
library(tidyverse)            #
library(RCurl)
frames <- image_morph(list.all.image_c, frames = 0.0025)
## Drawing the dots for the image
img <- image_read("../ExplicitImages/giphy.gif")
print(img)
list.all <- vector(mode = "list", length = length(img))
#### Get the face detection data from google
for (i in seq(length(img))) {
image_name <- paste("../ExplicitImages/gif", i, ".jpeg", sep = "")
image_write(img[i], path = image_name, format = "jpeg")
PicVisionStatsFace = getGoogleVisionResponse(image_name, feature = 'FACE_DETECTION', numResults = 40)
## Generating boundry for the face
xs1 <- PicVisionStatsFace$fdBoundingPoly$vertices[[1]][1][[1]]
ys1 <- PicVisionStatsFace$fdBoundingPoly$vertices[[1]][2][[1]]
## Generating landmarks like nose, eye brows
xs2 = PicVisionStatsFace$landmarks[[1]][[2]][[1]]
ys2 = PicVisionStatsFace$landmarks[[1]][[2]][[2]]
#
list.all[[i]] <- list(xs1, ys1, xs2, ys2)
}
## Drawing the dots for the image
img <- image_read("./ExplicitImages/giphy.gif")
print(img)
library(shiny); runApp('code/InterGrowthShinyApp.R')
runApp('code/InterGrowthShinyApp.R')
